{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "data = pd.read_pickle('Processed_data/data_processed.csv')\n",
    "\n",
    "#We have loaded the data in the form of sequence matrices\n",
    "#The raw data set was a set of 37,000 quotes and proverbs : Raw_data/data.json\n",
    "#Run the script 'process_data.py' to convert the raw data set of quotes to sequence matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vocabulary Dataset\n",
    "#Run 'process_data.py' to obtain it\n",
    "\n",
    "vocab = pd.read_csv('Processed_Data/vocab.csv')\n",
    "vocab = vocab['word'].values\n",
    "\n",
    "n_words = len(vocab)\n",
    "max_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[23649, 6395, 23362, 29104, 14769, 4501, 26129...</td>\n",
       "      <td>[6395, 23362, 29104, 14769, 4501, 26129, 18217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[23649, 24495, 26895, 22088, 11786, 1120, 2451...</td>\n",
       "      <td>[24495, 26895, 22088, 11786, 1120, 24519, 1996...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23649, 14233, 18516, 25586, 4006, 7759, 24928...</td>\n",
       "      <td>[14233, 18516, 25586, 4006, 7759, 24928, 32413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[23649, 24072, 5439, 20298, 30530, 4911, 21714...</td>\n",
       "      <td>[24072, 5439, 20298, 30530, 4911, 21714, 22063...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[23649, 14233, 11412, 1261, 20298, 24519, 1716...</td>\n",
       "      <td>[14233, 11412, 1261, 20298, 24519, 17165, 1235...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   X  \\\n",
       "0  [23649, 6395, 23362, 29104, 14769, 4501, 26129...   \n",
       "1  [23649, 24495, 26895, 22088, 11786, 1120, 2451...   \n",
       "2  [23649, 14233, 18516, 25586, 4006, 7759, 24928...   \n",
       "3  [23649, 24072, 5439, 20298, 30530, 4911, 21714...   \n",
       "4  [23649, 14233, 11412, 1261, 20298, 24519, 1716...   \n",
       "\n",
       "                                                   Y  \n",
       "0  [6395, 23362, 29104, 14769, 4501, 26129, 18217...  \n",
       "1  [24495, 26895, 22088, 11786, 1120, 24519, 1996...  \n",
       "2  [14233, 18516, 25586, 4006, 7759, 24928, 32413...  \n",
       "3  [24072, 5439, 20298, 30530, 4911, 21714, 22063...  \n",
       "4  [14233, 11412, 1261, 20298, 24519, 17165, 1235...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, every X training point is a sequence of words with the starting of the sentence marked as 'STARTPAD' [ID: 23649].\n",
    "Each input word represents a time step t. \n",
    "So, t(1) will be the start of the sentence.\n",
    "Its corresponding Y is the word from the next time step, t(n+1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert list to numpy arrays \n",
    "\n",
    "data['X'] = data['X'].apply(np.array)\n",
    "data['Y'] = data['Y'].apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data['X'].values\n",
    "Y = data['Y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayan\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#This step doesn't matter. We use this to make our arrays of the shape (35275,30)\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=0,truncating='post')\n",
    "Y = pad_sequences(maxlen=max_len, sequences=Y, padding=\"post\", value=0,truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35275, 30)\n",
      "(35275, 30)\n",
      "35275\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "n_sentences = X.shape[0]\n",
    "print(n_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24692, 30) (24692, 30)\n",
      "(7408, 30) (7408, 30)\n",
      "(3175, 30) (3175, 30)\n"
     ]
    }
   ],
   "source": [
    "#Split data\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "x_test,x_val,y_test,y_val = train_test_split(x_test, y_test, test_size=0.3)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)\n",
    "print(x_val.shape,y_val.shape)\n",
    "\n",
    "y_val = to_categorical(y_val,num_classes=n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Custom Generator to feed into the model\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def generator(batch_size):\n",
    "    x = np.zeros((batch_size,30))\n",
    "    y = np.zeros((batch_size,30))\n",
    "    while True:\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            index = np.random.randint(0,x_train.shape[0])\n",
    "            x[i] = x_train[index]\n",
    "            y[i] = y_train[index]\n",
    "        yield x, to_categorical(y,num_classes=n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Flatten,Dense, TimeDistributed, Dropout\n",
    "\n",
    "#Building a model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_words, output_dim=100, input_length=max_len))\n",
    "model.add(LSTM(units=100,return_sequences=True,recurrent_dropout=0.2))\n",
    "model.add(TimeDistributed(Dropout(0.2)))\n",
    "model.add(TimeDistributed(Dense(n_words,activation='softmax')))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           3243500   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 100)           80400     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 100)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 32435)         3275935   \n",
      "=================================================================\n",
      "Total params: 6,599,835\n",
      "Trainable params: 6,599,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  62/1646 [>.............................] - ETA: 2:43:37 - loss: 8.1575 - acc: 0.2067"
     ]
    }
   ],
   "source": [
    "batch_size = 15\n",
    "model.fit_generator(generator(batch_size),steps_per_epoch=x_train.shape[0]//batch_size,epochs=10,verbose=1,validation_data=(x_val,y_val),validation_steps=211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
