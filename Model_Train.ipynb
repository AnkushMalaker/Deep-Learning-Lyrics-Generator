{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/mayank/anaconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/mayank/anaconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,LSTM,Dense\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=''\n",
    "for ix in range(len(data)):\n",
    "    corpus+=data[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'E', 1: '-', 2: 'O', 3: 's', 4: 'd', 5: 'I', 6: 'b', 7: 'Q', 8: 'U', 9: 'Y', 10: '1', 11: '\"', 12: 'K', 13: ',', 14: '(', 15: 'w', 16: '2', 17: '9', 18: 'k', 19: 'N', 20: 'z', 21: 'V', 22: 'm', 23: 't', 24: 'a', 25: 'e', 26: 'c', 27: \"'\", 28: ')', 29: 'J', 30: '4', 31: 'y', 32: 'n', 33: '.', 34: 'F', 35: 'r', 36: 'H', 37: 'R', 38: '3', 39: 'A', 40: 'o', 41: 'C', 42: 'p', 43: 'v', 44: 'D', 45: 'l', 46: 'h', 47: '!', 48: 'g', 49: ']', 50: 'P', 51: 'B', 52: ':', 53: 'W', 54: 'L', 55: 'q', 56: '[', 57: 'T', 58: '?', 59: 'u', 60: 'M', 61: '0', 62: 'x', 63: '\\n', 64: 'G', 65: ' ', 66: 'f', 67: 'S', 68: 'i', 69: 'j'}\n"
     ]
    }
   ],
   "source": [
    "vocab=list(set(corpus))\n",
    "char_ix={c:i for i,c in enumerate(vocab)}\n",
    "ix_char={i:c for i,c in enumerate(vocab)}\n",
    "\n",
    "print(ix_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"text_data/char_ix.pkl\",\"wb\")\n",
    "pickle.dump(char_ix,f)\n",
    "f.close()\n",
    "\n",
    "w = open(\"text_data/ix_char.pkl\",\"wb\")\n",
    "pickle.dump(ix_char,w)\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=40\n",
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "next_char=[]\n",
    "for i in range(len(corpus)-maxlen-1):\n",
    "    sentences.append(corpus[i:i+maxlen])\n",
    "    next_char.append(corpus[i+maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.zeros((len(sentences),maxlen,vocab_size))\n",
    "y=np.zeros((len(sentences),vocab_size))\n",
    "for ix in range(len(sentences)):\n",
    "    y[ix,char_ix[next_char[ix]]]=1\n",
    "    for iy in range(maxlen):\n",
    "        X[ix,iy,char_ix[sentences[ix][iy]]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 40, 160)           147840    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 150)               186600    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 70)                10570     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 70)                0         \n",
      "=================================================================\n",
      "Total params: 345,010\n",
      "Trainable params: 345,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(160,return_sequences=True,input_shape=(maxlen,vocab_size)))\n",
    "model.add(LSTM(150,activation='tanh'))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(lr=0.01),loss='categorical_crossentropy',  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "157991/157991 [==============================] - 221s 1ms/step - loss: 1.7626 - acc: 0.4990\n",
      "Epoch 2/25\n",
      "157991/157991 [==============================] - 213s 1ms/step - loss: 1.3029 - acc: 0.6114\n",
      "Epoch 3/25\n",
      "157991/157991 [==============================] - 208s 1ms/step - loss: 1.1661 - acc: 0.6497\n",
      "Epoch 4/25\n",
      "157991/157991 [==============================] - 201s 1ms/step - loss: 1.0884 - acc: 0.6718\n",
      "Epoch 5/25\n",
      "157991/157991 [==============================] - 197s 1ms/step - loss: 1.1976 - acc: 0.6704\n",
      "Epoch 6/25\n",
      "157991/157991 [==============================] - 194s 1ms/step - loss: 1.0641 - acc: 0.6849\n",
      "Epoch 7/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 1.0220 - acc: 0.6943\n",
      "Epoch 8/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.9963 - acc: 0.7018\n",
      "Epoch 9/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.9725 - acc: 0.7059\n",
      "Epoch 10/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.8985 - acc: 0.7256\n",
      "Epoch 11/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.8914 - acc: 0.7272\n",
      "Epoch 12/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 1.1260 - acc: 0.6587\n",
      "Epoch 13/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 1.0258 - acc: 0.6870\n",
      "Epoch 14/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.9466 - acc: 0.7111\n",
      "Epoch 15/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.9263 - acc: 0.7166\n",
      "Epoch 16/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.8707 - acc: 0.7340\n",
      "Epoch 17/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.8519 - acc: 0.7388\n",
      "Epoch 18/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.8518 - acc: 0.7384\n",
      "Epoch 19/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.8574 - acc: 0.7362\n",
      "Epoch 20/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.8246 - acc: 0.7470\n",
      "Epoch 21/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.8130 - acc: 0.7497\n",
      "Epoch 22/25\n",
      "157991/157991 [==============================] - 196s 1ms/step - loss: 0.7981 - acc: 0.7536\n",
      "Epoch 23/25\n",
      "157991/157991 [==============================] - 195s 1ms/step - loss: 0.7947 - acc: 0.7537\n",
      "Epoch 24/25\n",
      "157991/157991 [==============================] - 196s 1ms/step - loss: 0.7824 - acc: 0.7586\n",
      "Epoch 25/25\n",
      "157991/157991 [==============================] - 196s 1ms/step - loss: 0.7686 - acc: 0.7624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0620a3e908>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=25,batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
